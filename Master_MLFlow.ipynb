{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9aSjFq3EGpueDv15c0Ke3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Spocklight/Fake_News_Detection/blob/master/Master_MLFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><center>Detección de noticias falsas</center></h1>\n",
        "<h3><center>Alejandro Sierra Fernández</center></h3>\n",
        "<h4><center>01/08/2022</center></h4>"
      ],
      "metadata": {
        "id": "wzjrX6iMQ76k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   <h2>Productivización del modelo</h2>\n",
        "\n",
        "<font color='darkblue'> En este Notebook vamos a poner un ejemplo sobre cómo productivizar el algoritmo RandomForest. Hemos elegido este algoritmo porque es el que mejor resultados nos ha dado a lo largo del estudio y por su simpleza en comparación con las redes neuronales. A pesar de que habíamos realizado ajuste de parámetros (RandomSearchCV) para encontrar aquellos más óptimos, en este caso vamos predecir empleando diferentes combinaciones de parámetros para ver las distintas métricas que se obtienen.</font>"
      ],
      "metadata": {
        "id": "tz9AzFayQ9hm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='darkblue'>Empleamos la herramienta de Opensource *MLFLOW* para gestionar el ciclo de vida de los modelos, registrando los resultados y parámetros para poder compararlos y permitiendo el control de versiones.\n",
        "\n",
        "También hacemos uso de *Ngrok*, que nos permitirá exponer a internet una URL generada dinámicamente y que apunta a un servicio web que se está generando en nuestra máquina local</font>"
      ],
      "metadata": {
        "id": "8glucFZyR5Vc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='darkblue'>Empezamos instalando e importando MLFlow</font>"
      ],
      "metadata": {
        "id": "MrMRolWuUv89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow --quiet\n",
        "!pip install pyngrok --quiet"
      ],
      "metadata": {
        "id": "SPEen6Wmfmxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6fa696-642b-45e3-fc62-5f187f485937"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 16.9 MB 8.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 44.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 209 kB 58.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 60.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 58.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59 kB 8.3 MB/s \n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 745 kB 9.6 MB/s \n",
            "\u001b[?25h  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='darkblue'> Configuramos el experimento en el que deseamos trabajar y le damos nombre</font>"
      ],
      "metadata": {
        "id": "ODe2mcSuV9Ez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "mlflow.set_experiment(experiment_name=\"mlflow demo2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oedMspobfoa-",
        "outputId": "de5e8f74-22cb-48b7-96e8-2d2825f37b53"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022/09/22 09:54:26 INFO mlflow.tracking.fluent: Experiment with name 'mlflow demo2' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='file:///content/mlruns/1', creation_time=1663840466888, experiment_id='1', last_update_time=1663840466888, lifecycle_stage='active', name='mlflow demo2', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora importamos las librerías necesarias para procesar los datos y para definir y entrenar nuestro modelo. Tambié importamos Ngrok"
      ],
      "metadata": {
        "id": "Ap8TVDA6WPEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "CfLFIB45rEql"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BkH466rDXJ0c"
      },
      "outputs": [],
      "source": [
        "import scipy as sp\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zny1TH1xXOkE",
        "outputId": "217eb09a-d986-4c11-e883-ce7558fb0c90"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: mlflow [OPTIONS] COMMAND [ARGS]...\n",
            "\n",
            "Options:\n",
            "  --version  Show the version and exit.\n",
            "  --help     Show this message and exit.\n",
            "\n",
            "Commands:\n",
            "  artifacts    Upload, list, and download...\n",
            "  azureml      Serve models on Azure ML.\n",
            "  db           Commands for managing an MLflow...\n",
            "  deployments  Deploy MLflow models to custom...\n",
            "  experiments  Manage experiments.\n",
            "  gc           Permanently delete runs in the\n",
            "               `deleted` lifecycle stage.\n",
            "\n",
            "  models       Deploy MLflow models locally.\n",
            "  pipelines    Run MLflow Pipelines and inspect...\n",
            "  run          Run an MLflow project from the...\n",
            "  runs         Manage runs.\n",
            "  sagemaker    Serve models on SageMaker.\n",
            "  server       Run the MLflow tracking server.\n",
            "  ui           Launch the MLflow tracking UI\n",
            "               for...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='darkblue'> Cargamos la información del Drive y la procesamos.</font>"
      ],
      "metadata": {
        "id": "9ZhuXzzHWpDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gT-i3qSXtVP",
        "outputId": "bad43f2e-79e7-4feb-dcae-b59376d18c5f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Fake_News/'\n",
        "pickle_in = open(path + 'ISOT_topic_sentiment_pickle', 'rb')\n",
        "ISOT = pickle.load(pickle_in)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFJF0QtdZ9-C",
        "outputId": "d5d5be26-ea4f-471a-f55f-b0edfc531a4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(ISOT, test_size=0.2, random_state=25)\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cN9rqStXw1f",
        "outputId": "ac88ee50-9b75-4b38-8cc1-b310bcae7fb8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30607, 28)\n",
            "(7652, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_1, count_0 = train[\"target\"].value_counts()\n",
        "\n",
        "class_0 = train[train.target=='Fake']\n",
        "class_1 = train[train.target=='True']\n",
        "class_1_under = class_1.sample(count_0)\n",
        "train_under = pd.concat([class_1_under, class_0], axis=0)\n",
        "\n",
        "train_under['target'].value_counts().plot(kind='bar', title='count (target)')\n",
        "train_under['target'].value_counts()\n",
        "train = train_under"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "vgQGjbYfXgoH",
        "outputId": "891bdbb0-0554-434c-98b5-604bbb54df5a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"target\"] = (train['target'] == 'True').astype(np.float32)  #True=1, Fake=0\n",
        "test[\"target\"] = (test['target'] == 'True').astype(np.float32)  #True=1, Fake=0"
      ],
      "metadata": {
        "id": "VVCCPNUdcYG2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizador = TfidfVectorizer(max_features=100,                  \n",
        "                               ngram_range=(1,3),\n",
        "                               min_df=10,\n",
        "                               max_df=0.50,\n",
        "                               lowercase=False)\n",
        "\n",
        "vector_title_train = vectorizador.fit_transform(train[\"clean_title\"])\n",
        "vector_text_train = vectorizador.fit_transform(train[\"clean_text\"])\n",
        "vector_title_test = vectorizador.fit_transform(test[\"clean_title\"])\n",
        "vector_text_test = vectorizador.fit_transform(test[\"clean_text\"])"
      ],
      "metadata": {
        "id": "iT5pvD85ca-R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extra_features_train_d = train[['Sentimiento_text', 'Análisis_text', 'Subjetividad_text', 'Sentimiento_title', 'Análisis_title', 'Subjetividad_title', 'topic_modelling_max',\n",
        "                              'prop_long_text', 'prop_long_title', 'prop_uppercase_text', 'prop_uppercase_title', 'token_title_len', 'token_text_len',\n",
        "                              'char_len_title', 'char_len_text']]\n",
        "\n",
        "extra_features_test_d = test[['Sentimiento_text', 'Análisis_text', 'Subjetividad_text', 'Sentimiento_title', 'Análisis_title', 'Subjetividad_title', 'topic_modelling_max',\n",
        "                              'prop_long_text', 'prop_long_title', 'prop_uppercase_text', 'prop_uppercase_title', 'token_title_len', 'token_text_len',\n",
        "                              'char_len_title', 'char_len_text']]\n",
        "\n",
        "sc = StandardScaler()\n",
        "extra_features_train = sc.fit_transform(extra_features_train_d)\n",
        "extra_features_test = sc.transform(extra_features_test_d)"
      ],
      "metadata": {
        "id": "YyWhOMB-ckAa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train[\"target\"].values\n",
        "X_train_text = sp.sparse.hstack((vector_text_train, extra_features_train),format='csr')\n",
        "X_train_title = sp.sparse.hstack((vector_title_train, extra_features_train),format='csr')\n",
        "\n",
        "y_test = test[\"target\"].values\n",
        "X_test_text = sp.sparse.hstack((vector_text_test, extra_features_test),format='csr')\n",
        "X_test_title = sp.sparse.hstack((vector_title_test, extra_features_test),format='csr')"
      ],
      "metadata": {
        "id": "yWVzwIEwcm-j"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_text = X_train_text.toarray()\n",
        "X_train_title = X_train_title.toarray()\n",
        "X_test_text = X_test_text.toarray()\n",
        "X_test_title = X_test_title.toarray()\n"
      ],
      "metadata": {
        "id": "4m8Zs-Cic0jm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='darkblue'> Cabe destacar que, siguiendo el mismo proceso, también podríamos haber hecho *pickle* con nuestro modelo ya entrenado y haberle dado como *input* nuevas noticias para lanzar predicciones. Sin embargo, de esta forma estudiamos en el servidor diferentes modelos con las diferentes métricas y resultados. De esta forma estamos simulando lo que podría ser el control de versiones</font>"
      ],
      "metadata": {
        "id": "QwkJiPtCW08n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='darkblue'> Definimos las métricas que vamos a emplear.</font>"
      ],
      "metadata": {
        "id": "lR7Oz3nSXnaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_metrics(actual, pred):\n",
        "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
        "        mae = mean_absolute_error(actual, pred)\n",
        "        r2 = r2_score(actual, pred)\n",
        "        return rmse, mae, r2"
      ],
      "metadata": {
        "id": "ZxQeKnoCto63"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='darkblue'> Definimos la función *train_model* y empezamos un* run de MLFlow* en el que serán cargadas las métricas y los parámetros de las diferentes versiones. Además, a la función le damos como entrada el número de nodos y la profundidad para poder generar algoritmos con diferentes combinaciones de parámetros y diferentes resultados.</font>"
      ],
      "metadata": {
        "id": "e6AdJPbwXrdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "def train_model(max_depth, n_estimators):\n",
        "  with mlflow.start_run():\n",
        "    RF_tuned=RandomForestClassifier(criterion = 'gini', max_depth = max_depth, n_estimators = n_estimators)\n",
        "    RF_tuned.fit(X_train_text,y_train)\n",
        "\n",
        "    print('Modelo entrenado')\n",
        "\n",
        "    y_pred = RF_tuned.predict(X_test_text)\n",
        "\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    model_accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(model_accuracy)\n",
        "\n",
        "    (rmse, mae, r2) = eval_metrics(y_test, y_pred)\n",
        "#Cargamos las métricas\n",
        "    mlflow.log_metric(\"accuracy\", model_accuracy)\n",
        "    mlflow.log_metric(\"rmse\", rmse)\n",
        "    mlflow.log_metric(\"r2\", r2)\n",
        "    mlflow.log_metric(\"mae\", mae)\n",
        "    mlflow.sklearn.log_model(RF_tuned, \"model\")\n",
        "\n",
        "  get_ipython().system_raw(\"mlflow ui --port 5000 &\")   #El siguiente bloque de código abre desde colab una url port 5000\n",
        "  from pyngrok import ngrok                             \n",
        "  ngrok.kill()\n",
        "  # Obtener authtoken de https://dashboard.ngrok.com/auth\n",
        "  NGROK_AUTH_TOKEN = \"2F6P0aUCJURTnlTm1Ak5yn3GhWP_2cbM1JToMZRHjPayqDzhu\"\n",
        "  ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "  ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "  print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)  #Ngrok nos devuelve la url pública para acceder a los resultados en tiempo real\n",
        "\n",
        "  #https://stackoverflow.com/questions/61615818/setting-up-mlflow-on-google-colab"
      ],
      "metadata": {
        "id": "eevwMvqZgJ8V"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='darkblue'> Finalmente llamamos al la función con diferentes combinaciones de parámetros.</font>"
      ],
      "metadata": {
        "id": "ZAtSqXg2cxZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(10, 250)\n",
        "train_model(10, 500)\n",
        "train_model(25, 250)\n",
        "train_model(50, 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaQL4HuKl70k",
        "outputId": "aceebea8-45ee-41bb-f01d-f651cfb42933"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo entrenado\n",
            "0.98170412963931\n",
            "MLflow Tracking UI: https://6be2-34-125-173-187.ngrok.io\n",
            "Modelo entrenado\n",
            "0.9827496079456352\n",
            "MLflow Tracking UI: https://43d1-34-125-173-187.ngrok.io\n",
            "Modelo entrenado\n",
            "0.9823575535807632\n",
            "MLflow Tracking UI: https://84e3-34-125-173-187.ngrok.io\n",
            "Modelo entrenado\n",
            "0.9826189231573444\n",
            "MLflow Tracking UI: https://8632-34-125-173-187.ngrok.io\n"
          ]
        }
      ]
    }
  ]
}